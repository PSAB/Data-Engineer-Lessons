{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"maps_and_lazy_evaluation_example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_of_songs = [\n",
    "    \"Despacito\",\n",
    "    \"Nice for what\",\n",
    "    \"No tears left to cry\",\n",
    "    \"Despacito\",\n",
    "    \"Havana\",\n",
    "    \"In my feelings\",\n",
    "    \"Nice for what\",\n",
    "    \"despacito\",\n",
    "    \"All the stars\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SparkContext has a method called ```parallelize``` that takes a Python object and distributes the object across the machines in your cluster, so Spark can use its functional features on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed_song_log = sc.parallelize(log_of_songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nest, use Spark function ```map``` to apply our lowercase lambda function to each song in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributed_song_log.map(lambda song: song.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While these steps may run instantly on a local machine, the Spark commands are actually using lazy evaluation; they haven't really converted the songs to lowercase yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark is still procrastinating to transform the songs into lowercase, since you might have several other processing steps like removing punctuation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark wants to wait until the last minute to see if it can streamline its work and combine these into a single stage before getting the actual data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to force Spark to take some action on the data, we can use the ```collect``` function, which gathers the results from all the machines in our cluster back to the machine running this jupyter notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['despacito',\n",
       " 'nice for what',\n",
       " 'no tears left to cry',\n",
       " 'despacito',\n",
       " 'havana',\n",
       " 'in my feelings',\n",
       " 'nice for what',\n",
       " 'despacito',\n",
       " 'all the stars']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributed_song_log.map(lambda song: song.lower()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Despacito',\n",
       " 'Nice for what',\n",
       " 'No tears left to cry',\n",
       " 'Despacito',\n",
       " 'Havana',\n",
       " 'In my feelings',\n",
       " 'Nice for what',\n",
       " 'despacito',\n",
       " 'All the stars']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributed_song_log.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the original dataset didn't change, as Spark makes a copy of its input data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
